+++
title = "Mensch und Maschine"
date = "2024-05-06"
draft = false
pinned = false
tags = ["Deutsch", "Reportage"]
image = "bild1.jpg"
footnotes = ""
+++
# Mensch und Maschine: Wie viel Macht haben wir noch?

{{<lead>}}
Algorithmen und künstliche Intelligenz werden immer prominenter, doch wie abhängig sind wir wirklich?
{{</lead>}} 

![Der Kontakt zwischen Mensch und Maschine wird immer häufiger und direkter.](bild1-transformed.jpeg)

In einer Pause zwischen zwei Lektionen Einführung Wirtschaft und Recht (EWR) sieht Nicolas Kiechler, Fachlehrperson für Wirtschaft und Recht am Gymnasium Kirchenfeld, wie ein Schüler mithilfe von Copilot, der künstlichen Intelligenz von Microsoft, eine ganze HTML-Datei in eine einzige Zeile umschreibt. Obwohl er einer der jüngsten Lehrkräfte an dem gesamten Gymnasium ist, kam er in seinem Studium nicht in Kontakt mit ähnlichen Technologien: «Es war nicht so verbreitet, wie es heute der Fall ist.» Schüler heutzutage haben mehr Freiheit: «Verschiedenste Male wird das benutzt», sagt Kiechler über ChatGPT. Neugierde ist doch normal, oder? Aus diesem Grund treffen wir uns einige Wochen später online zum Interview: ChatGPT und Schulen, sollte das erlaubt sein? Der Gymnasiallehrer ist der Meinung, die Benutzung dieser Technologie sollte in Bildungsinstitutionen sogar gefördert werden: «Es ist ein Hilfsmittel, das den Schülerinnen und Schülern zur Verfügung steht», so Kiechler. Auf die Frage, ob diese Werkzeuge ohne Einschränkungen zur Verfügung gestellt werden sollten, weiss er keine klare Antwort: «Wenn ich bei Chat-GPT im Beispiel mir irgendetwas generieren lasse, muss ich einfach in der Lage sein zu urteilen: Ist das jetzt etwas Gutes oder nicht?» Dafür müsse man die Materie auch zu einem gewissen Grad verstehen, das Urteilsvermögen der Schüler dazu könne jedoch fehlen. Der Umgang mit diesen generativen KIs müsste also bewusst gesteuert und kontrolliert werden. Eine Gefährdung sieht er bereits, es entstehe eine Faulheit. Wenn man alles manuell machen würde, müsse man für Microsoft Excel mehr wissen, als wenn man alles von einer KI generieren lassen würde. Die «Bequemlichkeit», die durch diese einfachere Lösung – Künstlicher Intelligenz – entstehe, sieht Nicolas Kiechler auch an der Berufsschule, an der er ebenfalls unterrichtet: «Dort werden Mails teilweise ausschliesslich mit ChatGPT geschrieben», schriftliche Texte zu verlangen, wäre «Voll der Fehler».

{{<box>}}

ChatGPT ist eine sprachbasierte künstliche Intelligenz, die seit Ende 2019 der Öffentlichkeit zur Verfügung steht. Die KI kann auf natürliche Weise mit Benutzern unterhalten und auf Fragen antworten. Die neueste Version (stand April 2024) kann sogar das Internet für den Benutzer durchsuchen – etwas, was der Vorgänger aus Sicherheitsgründen nicht konnte, was die Korrektheit der Antworten verbesserte, jedoch nicht fehlerfrei macht. 

{{</box>}}

## Ungleichheiten bleiben

Weder Menschen noch Algorithmen sind gänzlich neutral oder überall geeignet. In einem Bericht von algorithmwatch.ch  wird beschrieben, wie sogenannte «Applicant Tracking Systems», auch ATS genannt, benutzt werden. «Durch den Einsatz solcher Systeme können diskriminierende Muster verschärft werden oder gar neue entstehen», behauptet algorithmwatch.ch. Diese «Applicant Tracking Systems» sind in der Regel immer noch herkömmliche Abläufe, die vom Menschen programmiert werden. KI-basierte Systeme werden allerdings bereits in allen möglichen Anwendungen getestet  und dürften in Zukunft auch von verschiedenen Unternehmen eingesetzt werden, um Kosten einzusparen. In einer Untersuchung von Findhr.eu wurden ATS mit ausgebildeten Experten in diesem Gebiet verglichen. Sie kam zum Schluss, dass viele der Bewerbenden, die von den Fachpersonen als Top-Kandidaten ausgewählt wurden, von den ATS viel tiefer eingestuft wurden. rund? Findhr.eu vermutet, dass «Applicant Tracking Systems» nicht alle Lebensläufe und Bewerbungen gleich gut lesen könnten und diese in einer bestimmten Struktur bevorzugen würden.
Sogar Rassismus sei ein Problem, zeigt ein britischer Bericht von Findhr.eu. Die KI-basierten Systeme zeigten eine Tendenz, Migranten auszuschliessen, selbst wenn sie besser für den Job geeignet gewesen wären. Selbst wenn man die Hochschule im Ausland abgeschlossen hätte, würde man mit einer Wahrscheinlichkeit von ungefähr 80% eine tiefere Bewertung erhalten. Diese Ergebnisse seien nicht absolut und bräuchten weitere internationale Überprüfung und Bestätigung, jedoch ist ein beängstigender Trend sichtbar. Künstliche Intelligenzen nehmen rassistische und sexistische Angewohnheiten an, da sie von älteren Datensets lernen, in denen diese heute inkorrekten Haltungen präsent waren. Diese Algorithmen geben also nur die menschlichen rassistischen Muster wieder.
Gesellschaftliche Kritiken gegenüber diesen Verhaltensmustern können sich aber auch negativ auswirken: Die generative Bilderstellungs-KI von OpenAI, DALL-E, wurde dafür kritisiert, zu viele «weisse» Bilder zu erstellen, was in der «Imagen» KI von Google überkompensiert wurde: Historische Figuren werden teil-weise mit falscher Hautfarbe generiert. 

{{<box>}}

ATS oder Applicant Tracking Systems, auf Deutsch Bewerbermanagementsystem, sind Algorithmen, die Job-Kandidaten automatisch nach Qualifikation filtern und auswählen sollen. Dafür analysiert es Bewerbungen und vergleicht diese mit einer Datenbank, um die besten herauszufiltern.

{{</box>}}

## Sind wir KI-abhängig?

Als komfortables und unkompliziertes Hilfsmittel ist KI gerne die erste Anfragestelle bei Problemen. Entwickeln wir so eine Abhängigkeit? Eindeutig, findet Leutenegger: «Es wird so sein, wie es ist, und die Abhängigkeit ist da». Bereits heutzutage findet man diese: Die Bern-Lötschberg-Simplon-Bahn (BLS), kann ohne ihr Ressourcenplanungssystem langfristig nicht funktionieren. Im Gegensatz zu Kiechler  empfindet er diese Situation jedoch als weitaus weniger schlimm: «Ich finde, Technologie und die Möglichkeiten, die Technologie bieten, die sind brillant, das ist genial.» Massnahmen werden bei solch wichtigen Systemen aber immer ergriffen: «Wenn wir wissen, dass ein System für den operativen Betrieb des Unternehmens, also bei uns jetzt Zugfahren zum Beispiel, kritisch ist und dass man ohne dieses System nicht fahren kann, dann muss man einfach schauen, dass das System stabil ist und entsprechend dann, wenn die Organisation dahinter haben, wenn es eine Panne gibt, dass man dann sofort reagieren kann.» Eine Voreingenommenheit sieht er bei sich selbst natürlich auch, Angst haben muss man also nach ihm nicht, es sei keine andere Entwicklung, als es auch schon in der Vergangenheit gab. Als Beispiel gab er uns das Smartphone: Er sei ohne ein solches aufgewachsen, aber er würde es selbst nicht mehr freiwillig weglegen. Solche Veränderungen und Entwicklungen seien also nichts Neues in dem Sinn, Zweifel seien normal, doch Versuche, diese technische Entwicklung aufzuhalten, wären nutzlos: «Was technologisch möglich ist, wird gemacht. Immer. Irgendwo. Das ist so. Man kann die Innovation und die technologischen Möglichkeiten nicht einschränken, dass es nicht gemacht wird. Klappt nicht.» Sicherheit ist jedoch nicht das einzige Problem: Privatsphäre wird gerade intensiv von verschiedenen Autoritäten diskutiert. Gerade weil die Benutzung künstlicher Intelligenzen zunimmt und zunehmen wird, entstehen immer mehr Konflikte, zum Beispiel Urheberrechtsverletzungen bei Bildern, die verwendet wurden, um generative KIs zu trainieren. Diese urheberrechtlich geschützten Bilder können dann von der KI als «Inspiration» für «neue» Bilder benutzt werden. Laut Leutenegger ist das aber kein Grund zur Sorge, es würden sich in der Zukunft Regeln und Gesetzte einpendeln, mit denen schliesslich eine korrekte und faire Benutzung gewährleistet werden kann.

{{<box>}}

Das Ressourcenplanungssystem der BLS plant den Verkehr der Züge. Es teilt Lokführer auf gewisse Strecken, auf denen sie zertifiziert sind, zu, und weist ihnen einen bestimmten Zug zu.

{{</box>}}

## Entwicklung – Eine Gefahr für die Gesellschaft?

Algorithmen sind also grundsätzlich nicht gefährlich für den Menschen – oder etwa doch? Eines der Hauptthemen der aktuellen technologischen Entwicklung ist die Automatisierung von Arbeitsplätzen. Im vergangenen Jahrzehnt sind in Europa bereits über eineinhalb Millionen jobs durch die Automatisierung weggefallen, werden in Zukunft also Jobs eine wertvolle Seltenheit sein? Ganz klar nicht, meint Leutenegger: «Jede Technologie schafft mehr Arbeitsplätze, als sie zerstört.» Das heisst allerdings nicht, dass es gar keine Probleme gibt. «Man muss Leute ausbilden, die die neu geschaffenen Arbeitsplätze belegen, also ausüben. Und das Problem, es gibt dann immer wieder Verlierer. Nämlich diejenigen, die ihre Arbeitsplätze verlieren, wegen der Technologie.» Jedoch sollten in Zukunft eine beträchtliche Anzahl Stellen ersetzt werden und damit viele Arbeitnehmende gefährden, die Statistikwebsite Statista sieht bis zum Jahr 2025 über 7.5 Millionen Arbeitsplätze in Gefahr, wie akkurat diese Prognose ist wird sich jedoch noch herausstellen müssen.
Die Beziehung von Menschen und Maschinen ist insbesondere komplex, wenn es um Algorithmen oder Künstlichen Intelligenz geht Es ist unbestreitbar, dass wir in vielen Bereichen unseres Lebens zunehmend von Technologie abhängig werden.
Es ist daher entscheidend, dass man einen bewussten und informierten Umgang mit diesen Technologien fördert. Man muss sicherstellen, dass sie auf eine Weise eingesetzt werden, die unsere Werte respektiert und fördert, und dass wir die notwendigen Fähigkeiten und Kenntnisse entwickeln, um sie effektiv und verantwortungsvoll zu nutzen. 
Seit Jahren werden allerhand Algorithmen in jeglichen Einsatzgebieten eingesetzt, oft ohne, dass dies dem Benutzer überhaupt bewusst wird. Ob man nun einfach den schnellsten Weg zur nächsten Migros wissen möchte oder online für Geschenke für ein Familienmitglied sucht: Beinahe alles wird von Algorithmen unterstützt oder erfasst. Blindes Vertrauen birgt aber auch Risiken: Mindestens eine Person kam ums Leben, weil ihr Navigationssystem anzeigte, eine Fährverbindung sei mit dem Auto überquerbar.
Trotz solchen Fehlern werden diese Systeme weiterhin eingesetzt und weiterentwickelt, obwohl diese Technologien, die unser Leben einfacher machen sollen, sogar Todesfälle verursachen. Doch die Frage ist: Wie gross ist die Gefährdung für den Grossteil der Menschen? Unter dem Strich, nicht sehr gross, da die einzelnen Anwendungen keine starken Risiken bergen, jeder benutzt hunderte Algorithmen am Tag, sei es am Handy, an Ticketautomaten oder sogar einen einfachen Taschenrechner, meist ohne jegliche Nebenwirkungen.\
Letztendlich liegt die Macht nicht in den Maschinen selbst, sondern in der Art und Weise, wie man  sie nutzt und kontrolliert. Es liegt an der Gesellschaft, das Gleichgewicht zu finden und zu bestimmen, wie diese Werkzeuge einsetzt werden sollen, und mit diesem Gleichgewicht wird auch Nicolas Kiechler weiterhin unbesorgt seiner Neugierde nachgehen können. 

**Text: Alec und Aaron**

## Quellenverzeichnis

* Paksy Plackis-Cheng, Dr. Tejo Chalasani, Sabrina Palme, et al. (10. Dezember, 2023). Ensuring Human Intelligence in AI Hiring Tools. Zugriff am 03. März 2024, von 
  https://findhr.eu/wp-content/uploads/2024/01/FINDHR-Expert-Report_by-Paksy-Plackis-Cheng-et-al.pdf
* Algorithmwatch.ch. (Datum unbekannt). Diskriminierung 2.0: Wie Rassismus in Algorithmen weiterlebt. Zugriff am 03. März 2024, von 
  https://algorithmwatch.ch/de/tag-gegen-rassismus-21-marz/
* BCG. (27. November, 2017). Prognose zur Anzahl der potenziell gefährdeten Arbeitsplätze durch die Automatisierung in Deutschland nach Berufen bis zum Jahr 2025* (in Millionen) \[Graph]. In Statista. Zugriff am 05. Mai 2024, von https://de.statista.com/statistik/daten/studie/814326/umfrage/prognose-gefaehrdete-arbeitsplaetze-durch-die-automatisierung-in-deutschland/
* Titel